{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep CNNs for Violin Melody Extraction from Polyphonic Music Signals\n",
    "\n",
    "#### Contributors: Mr. David Fong, Dr. Patrick Naylor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard modules\n",
    "import numpy as np\n",
    "# import custom modules\n",
    "import chooseRepresentation\n",
    "import preprocessing\n",
    "import training\n",
    "import postprocessing\n",
    "import evaluation\n",
    "import predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_proj = #fill in with path\n",
    "path_data = path_proj + '/data'\n",
    "\n",
    "path_ChooseFeatures = path_data + '/choose_Features'\n",
    "path_violin = path_ChooseFeatures + '/violin_file.wav'\n",
    "\n",
    "path_ME1 = path_data + '/ME1'\n",
    "path_train_ME1 = path_ME1 + '/TRAINING'\n",
    "path_trainAugmented_ME1 = path_ME1 + '/TRAINING_AUGMENTED'\n",
    "path_test_ME1 = path_ME1 + '/TEST'\n",
    "\n",
    "path_ME2 = path_data + '/ME2'\n",
    "path_train_ME2 = path_ME2 + '/TRAINING'\n",
    "path_trainAugmented_ME2 = path_ME2 + '/TRAINING_AUGMENTED'\n",
    "path_test_ME2 = path_ME2 + '/TEST'\n",
    "\n",
    "path_MTME = path_data + '/MTME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=16000\n",
    "hopSize_Sec=0.010\n",
    "noteMin='G3'\n",
    "noteMax='F#7'\n",
    "H=2\n",
    "K=192\n",
    "B=48\n",
    "T=11\n",
    "numClasses = 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Input Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create solo violin File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_violin = chooseRepresentation.concatenateAudio(path_ChooseFeatures)\n",
    "data, fs = chooseRepresentation.convertWavToArray(path_violin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Plot Spectrograms of solo violin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNorm_Mel, SNorm_STFT, SNorm_CQT, SNorm_HCQT = chooseRepresentation.plotSpectrograms(data,fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Plot HCQT and Input Feature of polyphonic audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_exampleData = path_test_ME1 + '/VS01.wav'\n",
    "exampleData,exampleFs = chooseRepresentation.convertWavToArrayNew(path_exampleData)\n",
    "SFinal_HCQT = chooseRepresentation.plotHCQT(exampleData) \n",
    "inputFeatureExample = chooseRepresentation.plotInputFeature(exampleData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Polyphonic Violin Melody Extraction CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clean Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.cleanTestGTME(path_test_ME1)\n",
    "preprocessing.cleanTrainGTME(path_train_ME1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Downmix to mono and Downsample to 16kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.downmixAudio(path_test_ME1)\n",
    "preprocessing.downmixAudio(path_train_ME1)\n",
    "preprocessing.downsampleAudio(path_test_ME1,fs)\n",
    "preprocessing.downsampleAudio(path_train_ME1,fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Augment training data by pitch shifting up by up to 3 semitones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.augmentDataME(path_train_ME1,path_trainAugmented_ME1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Extract Input Features & Labels for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest, yTest = preprocessing.extractFeaturesME(path_test_ME1, T, fs, hopSize_Sec, noteMin, H, K, B)\n",
    "preprocessing.saveInputOutputArrays(XTest, yTest, 'XTest_ME.npy', 'yTest_ME.npy', path_ME1)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Get list of filenames in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = preprocessing.listAudioFilenames(path_train_ME1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Extract Input Features & Labels for each piece in Training Set (do one by one, changing i from 0 to len(pieces)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selPiece = pieces[i]\n",
    "XTrain, yTrain = preprocessing.extractFeaturesME(path_trainAugmented_ME1+'/'+selPiece, T, fs, hopSize_Sec, noteMin, H, K, B)\n",
    "preprocessing.saveInputOutputArrays(XTrain, yTrain, 'XTrain_ME_'+selPiece+'.npy', 'yTrain_ME_'+selPiece+'.npy', path_ME1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Subsample training data by factor 10.00 to get appropriately sized data for RAM (do one by one, changing i from 0 to len(pieces)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XFull, yFull = preprocessing.loadArrays(path_ME1, 'XTrain_ME_'+selPiece+'.npy', 'yTrain_ME_'+selPiece+'.npy')\n",
    "XSampled, ySampled = preprocessing.pickSubsetfromData(XFull, yFull, reductionFactor=10.00)\n",
    "preprocessing.saveInputOutputArrays(XSampled, ySampled, 'XTrain_ME_'+selPiece+'subset'+'.npy', 'yTrain_ME_'+selPiece+'subset'+'.npy', path_ME1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Concatenate subsampled data to form final training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XProv, yProv = preprocessing.loadArrays(path_ME1, 'XTrain_ME_'+pieces[0]+'subset'+'.npy','yTrain_ME_'+pieces[0]+'subset'+'.npy')\n",
    "for i in range(1,len(pieces),1):\n",
    "    selPiece = pieces[i]\n",
    "    XLoaded, yLoaded = preprocessing.loadArrays(path_ME1, 'XTrain_ME_'+selPiece+'subset'+'.npy','yTrain_ME_'+selPiece+'subset'+'.npy')\n",
    "    XProv = np.concatenate((XProv, XLoaded), axis=0)\n",
    "    yProv = np.concatenate((yProv, yLoaded), axis=0)\n",
    "\n",
    "preprocessing.saveInputOutputArrays(XProv, yProv, 'XTrain_ME'+'.npy', 'yTrain_ME'+'.npy', path_ME1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Check that all label data is within required range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TrainMECNN = preprocessing.loadLabelArray(path_ME1, 'yTrain_ME.npy')\n",
    "counter=0\n",
    "for el in y_TrainMECNN:\n",
    "    if el > 48:\n",
    "        print(\"NOTE TOO HIGH AT \"+str(el))\n",
    "    counter = counter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: plot distribution of f0 labels for full and final training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ySubset = preprocessing.loadLabelArray(path_ME1,'yTrain_ME'+'.npy')\n",
    "yProv = preprocessing.loadLabelArray(path_ME1,'yTrain_ME_'+pieces[0]+'.npy')\n",
    "for i in range(1,len(pieces),1):\n",
    "    selPiece = pieces[i]\n",
    "    yLoaded = preprocessing.loadLabelArray(path_ME1,'yTrain_ME_'+selPiece+'.npy')\n",
    "    yProv = np.concatenate((yProv, yLoaded), axis=0)\n",
    "\n",
    "preprocessing.plotLabelDistributions(yProv,ySubset,'poly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for Monophonic Violin Melody Extraction CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Clean Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.cleanTestGTME(path_test_ME2)\n",
    "preprocessing.cleanTrainGTME(path_train_ME2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Downmix to mono and Downsample to 16kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.downmixAudio(path_test_ME2)\n",
    "preprocessing.downmixAudio(path_train_ME2)\n",
    "preprocessing.downsampleAudio(path_test_ME2,fs)\n",
    "preprocessing.downsampleAudio(path_train_ME2,fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Augment training data by pitch shifting up by up to 3 semitones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.augmentDataME(path_train_ME2,path_trainAugmented_ME2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get list of filenames in training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = preprocessing.listAudioFilenames(path_train_ME2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Extract Input Features & Labels for each piece in Training Set (do one by one, changing i from 0 to len(pieces)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selPiece = pieces[i]\n",
    "XTrain, yTrain = preprocessing.extractFeaturesME(path_trainAugmented_ME2+'/'+selPiece, T, fs, hopSize_Sec, noteMin, H, K, B)\n",
    "preprocessing.saveInputOutputArrays(XTrain, yTrain, 'XTrain_ME_'+selPiece+'.npy', 'yTrain_ME_'+selPiece+'.npy', path_ME2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Subsample training data by factor 2.22 to get appropriately sized data for RAM (do one by one, changing i from 0 to len(pieces)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selPiece = pieces[i]\n",
    "XFull, yFull = preprocessing.loadArrays(path_ME2, 'XTrain_ME_'+selPiece+'.npy', 'yTrain_ME_'+selPiece+'.npy')\n",
    "XSampled, ySampled = preprocessing.pickSubsetfromData(XFull, yFull, reductionFactor=2.22)\n",
    "preprocessing.saveInputOutputArrays(XSampled, ySampled, 'XTrain_ME_'+selPiece+'subset'+'.npy', 'yTrain_ME_'+selPiece+'subset'+'.npy', path_ME2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Concatenate subsampled data to form final training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XProv, yProv = preprocessing.loadArrays(path_ME2, 'XTrain_ME_'+pieces[0]+'subset'+'.npy','yTrain_ME_'+pieces[0]+'subset'+'.npy')\n",
    "for i in range(1,len(pieces),1):\n",
    "    selPiece = pieces[i]\n",
    "    XLoaded, yLoaded = preprocessing.loadArrays(path_ME2, 'XTrain_ME_'+selPiece+'subset'+'.npy','yTrain_ME_'+selPiece+'subset'+'.npy')\n",
    "    XProv = np.concatenate((XProv, XLoaded), axis=0)\n",
    "    yProv = np.concatenate((yProv, yLoaded), axis=0)\n",
    "\n",
    "preprocessing.saveInputOutputArrays(XProv, yProv, 'XTrain_ME'+'.npy', 'yTrain_ME'+'.npy', path_ME2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Check that all label data is within required range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_TrainMECNN = preprocessing.loadLabelArray(path_ME2, 'yTrain_ME.npy')\n",
    "counter=0\n",
    "for el in y_TrainMECNN:\n",
    "    if el > 48:\n",
    "        print(\"NOTE TOO HIGH AT \"+str(el))\n",
    "    counter = counter+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Plot distribution of f0 labels for full and final training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ySubset = preprocessing.loadLabelArray(path_ME2,'yTrain_ME'+'.npy')\n",
    "yProv = preprocessing.loadLabelArray(path_ME2,'yTrain_ME_'+pieces[0]+'.npy')\n",
    "for i in range(1,len(pieces),1):\n",
    "    selPiece = pieces[i]\n",
    "    yLoaded = preprocessing.loadLabelArray(path_ME2,'yTrain_ME_'+selPiece+'.npy')\n",
    "    yProv = np.concatenate((yProv, yLoaded), axis=0)\n",
    "\n",
    "preprocessing.plotLabelDistributions(yProv,ySubset,'mono')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train and Evaluate Polyphonic Melody Extraction Single CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Training and Test Set Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain_PolyMECNN, yTrain_PolyMECNN = preprocessing.loadArrays(path_ME1, 'XTrain_ME'+'.npy','yTrain_ME'+'.npy')\n",
    "XTest_PolyMECNN, yTest_PolyMECNN = preprocessing.loadArrays(path_ME1, 'XTest_ME'+'.npy','yTest_ME'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: One hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrainOHE_PolyMECNN, yTestOHE_PolyMECNN = training.encodeLabels(yTrain_PolyMECNN,yTest_PolyMECNN,numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Execute random initialisation of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "initialisation = training.initialiseWithSeed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PolyMECNN_Built = training.buildSingleMECNN(rows=K,columns=T,channels=H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Set model Type and Number, and save model diagram (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = 'PolyMECNN'\n",
    "modelNum = 1\n",
    "training.saveModelDiagram(PolyMECNN_Built, nameModel=modelType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Set hyperparameters for training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, batchSize, optimiser, lossFunction = training.setHyperparamsPolyMECNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Compile Model with loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolyMECNN_Compiled = training.compileModel(PolyMECNN_Built, lossFunction, optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolyMECNN_Trained, PolyMECNN_History = training.trainModel(PolyMECNN_Compiled, \n",
    "                                                           XTrain_PolyMECNN, yTrainOHE_PolyMECNN, \n",
    "                                                           E, batchSize,  \n",
    "                                                           nameModel=modelType, numModel=modelNum, pathSave=path_ME1,\n",
    "                                                           vsplit=False, vsplitfactor=0.1,\n",
    "                                                           XVal=XTest_PolyMECNN, yVal=yTestOHE_PolyMECNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Plot evolution of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plotModelHistory(PolyMECNN_History, \n",
    "                          modelType, modelNum,\n",
    "                          E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate Model on Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PolyMECNN_Loaded = training.loadpretrainedmodel(path_ME1+'/'+modelType+'_'+str(modelNum)+'.h5')\n",
    "PolyMECNN_TestLoss, PolyMECNN_TestAcc = training.evaluateModel(PolyMECNN_Loaded, batchSize, \n",
    "                                                                       XTest_PolyMECNN, yTestOHE_PolyMECNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train and Evaluate Monophonic Melody Extraction Single CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Training and Test Set Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain_MonoMECNN, yTrain_MonoMECNN = preprocessing.loadArrays(path_ME2, 'XTrain_ME'+'.npy','yTrain_ME'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: One hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrainOHE_MonoMECNN = training.encodeLabelsSingle(yTrain_MonoMECNN,numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Execute random initialisation of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "initialisation = training.initialiseWithSeed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonoMECNN_Built = training.buildSingleMECNN(rows=K,columns=T,channels=H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Set Model Type and Number, and save model diagram (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = 'MonoMECNN'\n",
    "modelNum = 1\n",
    "training.saveModelDiagram(MonoMECNN_Built, nameModel=modelType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Set hyperparameters for training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, batchSize, optimiser, lossFunction = training.setHyperparamsMonoMECNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Compile Model with loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonoMECNN_Compiled = training.compileModel(MonoMECNN_Built, lossFunction, optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonoMECNN_Trained, MonoMECNN_History = training.trainModel(MonoMECNN_Compiled, \n",
    "                                                           XTrain_MonoMECNN, yTrainOHE_MonoMECNN, \n",
    "                                                           E, batchSize,  \n",
    "                                                           nameModel=modelType, numModel=modelNum, pathSave=path_ME2,\n",
    "                                                           vsplit=True, vsplitfactor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Plot evolution of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plotModelHistory(MonoMECNN_History, \n",
    "                          modelType, modelNum,\n",
    "                          E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate Model on Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MonoMECNN_Loaded = training.loadpretrainedmodel(path_ME2+'/'+modelType+'_'+str(modelNum)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrices and get predictions for Single CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set Model Type, Number and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = 'PolyMECNN'\n",
    "modelNum = 1\n",
    "selPath = path_ME1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load labels and one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTestPoly, yTestPoly = preprocessing.loadArrays(path_ME1, 'XTest_ME'+'.npy','yTest_ME'+'.npy')\n",
    "yTestPolyOHE = training.encodeLabelsSingle(yTestPoly, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compute confusion matrix for CNN's predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedCNN = training.loadpretrainedmodel(selPath+'/'+modelType+'_'+str(modelNum)+'.h5')\n",
    "lowestMIDIGT, labelListGT, classNamesGT = training.getClassNames(yTestPoly)\n",
    "yPredPoly = predicting.predictOutputSingle(loadedCNN, XTestPoly)\n",
    "lowestMIDIPred, labelListPred, classNamesPred = training.getClassNames(yPredPoly)\n",
    "ConfusionMatrix, Predictions = training.plotConfusionMatrixSingle(loadedCNN, modelType, modelNum,\n",
    "                                                                  XTestPoly, yTestPolyOHE, \n",
    "                                                                  classNamesPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing for Single CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Save array of all f0 Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = preprocessing.listAudioFilenames(path_train_ME1)\n",
    "f0TrainingLabels = postprocessing.buildf0labelStream(path_train_ME1, pieces)\n",
    "preprocessing.saveLabelArray(f0TrainingLabels, 'f0TrainingLabels'+'.npy', path_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Test Set Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTestPoly, yTestPoly = preprocessing.loadArrays(path_ME1, \n",
    "                                                'XTest_ME'+'.npy', 'yTest_ME'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load pre-trained CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Singlemodel = training.loadpretrainedmodel(path_ME1+'/'+'PolyMECNN_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Load f0 Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0TrainingLabels = preprocessing.loadLabelArray(path_data, 'f0TrainingLabels'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Get Smoothed Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredPolySmoothed = postprocessing.getsmoothedf0Traj(f0TrainingLabels, yTestPoly, Singlemodel, False, XTestPoly, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compare accuracy obtained with smoothed over raw f0 trajectory on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredPolyRaw = predicting.predictOutputSingle(Singlemodel, XTestPoly)\n",
    "checksSmoothed, degreeSimilaritySmoothed = postprocessing.checkSimilarity(yTestPoly, yPredPolySmoothed)\n",
    "checksRaw, degreeSimilarityRaw = postprocessing.checkSimilarity(yTestPoly, yPredPolyRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for Violin Melody Extraction Multi-Task CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Subsample training data for Polyphonic VME CNN to form Target Task training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XPoly, yPoly = preprocessing.loadArrays(path_ME1, 'XTrain_ME'+'.npy', 'yTrain_ME'+'.npy')\n",
    "XPolyHalved, yPolyHalved = preprocessing.pickNumFeatures(XPoly, yPoly, 150000)\n",
    "preprocessing.saveInputOutputArrays(XPolyHalved, yPolyHalved, 'XTrainPoly_MTME'+'.npy', 'yTrainPoly_MTME'+'.npy', path_MTME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Subsample training data for Polyphonic VME CNN to form Auxiliary Task training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XMono, yMono = preprocessing.loadArrays(path_ME2, 'XTrain_ME'+'.npy', 'yTrain_ME'+'.npy')\n",
    "XMonoHalved, yMonoHalved = preprocessing.pickNumFeatures(XMono, yMono, 150000)\n",
    "preprocessing.saveInputOutputArrays(XMonoHalved, yMonoHalved, 'XTrainMono_MTME'+'.npy', 'yTrainMono_MTME'+'.npy', path_MTME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build, Train and Evaluate Violin Melody Extraction  Multi-Task CNN (Do each of 5 configurations one-by-one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Training and Test Set Arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainPoly_MTMECNN, yTrainPoly_MTMECNN = preprocessing.loadArrays(path_MTME, 'XTrainPoly_MTME'+'.npy',\n",
    "                                                                  'yTrainPoly_MTME'+'.npy')\n",
    "XTrainMono_MTMECNN, yTrainMono_MTMECNN = preprocessing.loadArrays(path_MTME, 'XTrainMono_MTME'+'.npy',\n",
    "                                                                  'yTrainMono_MTME'+'.npy')\n",
    "XTestPoly_MTMECNN, yTestPoly_MTMECNN = preprocessing.loadArrays(path_ME1, 'XTest_ME'+'.npy','yTest_ME'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: One hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrainPolyOHE_MTMECNN = training.encodeLabelsSingle(yTrainPoly_MTMECNN, numClasses)\n",
    "yTrainMonoOHE_MTMECNN = training.encodeLabelsSingle(yTrainMono_MTMECNN, numClasses)\n",
    "yTestPolyOHE_MTMECNN = training.encodeLabelsSingle(yTestPoly_MTMECNN, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Execute random initialisation of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "initialisation = training.initialiseWithSeed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTMECNN_Built = training.buildMTMECNN(rows=K,columns=T,channels=H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Set model type and number (do one by one, changing i from 0 to 4), and save model diagram (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = 'MTMECNN'\n",
    "modelNum = [1, 2, 3, 4, 5]\n",
    "selModelNum = modelNum[i]\n",
    "training.saveModelDiagram(MTMECNN_Built, nameModel=modelType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Set hyperparameters for training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, batchSize, optimiser, lossFunction = training.setHyperparamsMTMECNN()\n",
    "lossWeights = training.getLossWeights(selModelNum) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Compile Model with loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTMECNN_Compiled = training.compileMultiTaskModel(MTMECNN_Built, lossFunction, lossWeights, optimiser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Train CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTMECNN_Trained, MTMECNN_History = training.trainMultiTaskModel(MTMECNN_Compiled, \n",
    "                                                                XTrainPoly_MTMECNN, yTrainPolyOHE_MTMECNN, \n",
    "                                                                XTrainMono_MTMECNN, yTrainMonoOHE_MTMECNN,\n",
    "                                                                E, batchSize,  \n",
    "                                                                nameModel=modelType, numModel=selModelNum, pathSave=path_MTME,\n",
    "                                                                vsplitfactor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Plot evolution of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.plotMultiTaskModelHistory(MTMECNN_History, \n",
    "                                   modelType, selModelNum,\n",
    "                                   E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTMECNN_Loaded = training.loadpretrainedmodel(path_MTME+'/'+modelType+'_'+str(selModelNum)+'.h5')\n",
    "MTMECNN_Metrics, MTMECNN_Score, MTMECNN_TestLoss, MTMECNN_TestAcc = training.evaluateMultiTaskModel(MTMECNN_Loaded, batchSize, \n",
    "                                                                                                    XTestPoly_MTMECNN, yTestPolyOHE_MTMECNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrices and get predictions for Multi-Task CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set model type, number and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = 'MTMECNN'\n",
    "modelNum = [1, 2, 3, 4, 5]\n",
    "selPath = path_MTME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load labels and one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTestMT, yTestMT = preprocessing.loadArrays(path_ME1, 'XTest_ME'+'.npy','yTest_ME'+'.npy')\n",
    "yTestMTOHE = training.encodeLabelsSingle(yTestMT, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compute confusion matrices for each CNN's predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in modelNum:\n",
    "    loadedCNN = training.loadpretrainedmodel(selPath+'/'+modelType+'_'+str(num)+'.h5')\n",
    "    lowestMIDIGT, labelListGT, classNamesGT = training.getClassNames(yTestMT)\n",
    "    yPredMT = predicting.predictOutputMT(loadedCNN, [XTestMT, XTestMT])\n",
    "    lowestMIDIPred, labelListPred, classNamesPred = training.getClassNames(yPredMT)\n",
    "    ConfusionMatrix = training.plotConfusionMatrixMT(loadedCNN, modelType, num,\n",
    "                                                     [XTestMT, XTestMT],\n",
    "                                                     [yTestMTOHE, yTestMTOHE], \n",
    "                                                     classNamesPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing for Multi-Task CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Test Set Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTestPoly, yTestPoly = preprocessing.loadArrays(path_ME1, \n",
    "                                                'XTest_ME'+'.npy', 'yTest_ME'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load pre-trained CNN Model (do one-by-one, changing i from 0 to 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTmodelfilenames = ['MTMECNN_1.h5', 'MTMECNN_2.h5', 'MTMECNN_3.h5', 'MTMECNN_4.h5', 'MTMECNN_5.h5']\n",
    "MTmodel = training.loadpretrainedmodel(path_MTME+'/'+MTmodelfilenames[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load f0 Training Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0TrainingLabels = preprocessing.loadLabelArray(path_data, 'f0TrainingLabels'+'.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get Smoothed Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredPolySmoothed = postprocessing.getsmoothedf0Traj(f0TrainingLabels, yTestPoly, MTmodel, True, XTestPoly, numClasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Compare accuracy obtained with smoothed over raw f0 trajectory on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredPolyRaw = predicting.predictOutputMT(MTmodel, XTestPoly)\n",
    "checksSmoothed, degreeSimilaritySmoothed = postprocessing.checkSimilarity(yTestPoly, yPredPolySmoothed)\n",
    "checksRaw, degreeSimilarityRaw = postprocessing.checkSimilarity(yTestPoly, yPredPolyRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate melody extraction systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Test Set Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTestPoly, yTestPoly = preprocessing.loadArrays(path_ME1, \n",
    "                                                'XTest_ME'+'.npy', 'yTest_ME'+'.npy') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define label file, models to evaluate and model names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelFile = 'f0TrainingLabels.npy'\n",
    "modelsEval = ['PolyMECNN_1.h5','MTMECNN_1.h5','MTMECNN_2.h5','MTMECNN_3.h5','MTMECNN_4.h5','MTMECNN_5.h5']\n",
    "modelNames = ['Melodia','Deep Salience Map CNN',\n",
    "             'Violin Melody Extraction Single CNN without smoothing','Violin Melody Extraction Single CNN with smoothing',\n",
    "             'Violin Melody Extraction MT-CNN 1 without smoothing','Violin Melody Extraction MT-CNN 1 with smoothing',\n",
    "             'Violin Melody Extraction MT-CNN 2 without smoothing','Violin Melody Extraction MT-CNN 2 with smoothing',\n",
    "             'Violin Melody Extraction MT-CNN 3 without smoothing','Violin Melody Extraction MT-CNN 3 with smoothing',\n",
    "             'Violin Melody Extraction MT-CNN 4 without smoothing','Violin Melody Extraction MT-CNN 4 with smoothing',\n",
    "             'Violin Melody Extraction MT-CNN 5 without smoothing','Violin Melody Extraction MT-CNN 5 with smoothing',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Get ground truth arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0TrajGT = evaluation.getF0TrajfromF0Labels(yTestPoly)\n",
    "f0CentsGT, voicingGT = evaluation.getf0CentsVoicingArrays(f0TrajGT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate Melodia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMelodia, f0TrajMelodia = evaluation.getMelodiaf0Traj(path_test_ME1, fs, noteMin, noteMax, hopSize_Sec, yTestPoly)\n",
    "f0CentsMelodia, voicingMelodia = evaluation.getf0CentsVoicingArrays(f0TrajMelodia)\n",
    "VR_Melodia, VFA_Melodia, RPA_Melodia, RCA_Melodia, OA_Melodia = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                        voicingMelodia, f0CentsMelodia, \n",
    "                                                                                        modelNames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate DSM CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesDSMCNN, f0TrajDSMCNN = evaluation.getDSMCNNf0Traj(path_test_ME1, hopSize_Sec, fs, noteMin, noteMax, yTestPoly)\n",
    "f0CentsDSMCNN, voicingDSMCNN = evaluation.getf0CentsVoicingArrays(f0TrajDSMCNN)\n",
    "VR_DSMCNN, VFA_DSMCNN, RPA_DSMCNN, RCA_DSMCNN, OA_DSMCNN = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                   voicingDSMCNN, f0CentsDSMCNN, \n",
    "                                                                                   modelNames[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Evaluate PolyMECNN_1 Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesPolyMECNN1R, f0TrajPolyMECNN1R = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                                 modelsEval[0], path_ME1, labelFile, path_data, \n",
    "                                                                 smooth=False, isMT=False)\n",
    "f0CentsPolyMECNN1R, voicingPolyMECNN1R = evaluation.getf0CentsVoicingArrays(f0TrajPolyMECNN1R)\n",
    "VR_PolyMECNN1R, VFA_PolyMECNN1R, RPA_PolyMECNN1R, RCA_PolyMECNN1R, OA_PolyMECNN1R = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                            voicingPolyMECNN1R, f0CentsPolyMECNN1R, \n",
    "                                                                                                            modelNames[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Evaluate PolyMECNN_1 Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesPolyMECNN1S, f0TrajPolyMECNN1S = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                                 modelsEval[0], path_ME1, labelFile, path_data, \n",
    "                                                                 smooth=True, isMT=False)\n",
    "f0CentsPolyMECNN1S, voicingPolyMECNN1S = evaluation.getf0CentsVoicingArrays(f0TrajPolyMECNN1S)\n",
    "VR_PolyMECNN1S, VFA_PolyMECNN1S, RPA_PolyMECNN1S, RCA_PolyMECNN1S, OA_PolyMECNN1S = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                            voicingPolyMECNN1S, f0CentsPolyMECNN1S, \n",
    "                                                                                                            modelNames[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate MTMECNN_1 Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN1R, f0TrajMTMECNN1R = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[1], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=False, isMT=True)\n",
    "f0CentsMTMECNN1R, voicingMTMECNN1R = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN1R)\n",
    "VR_MTMECNN1R, VFA_MTMECNN1R, RPA_MTMECNN1R, RCA_MTMECNN1R, OA_MTMECNN1R = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN1R, f0CentsMTMECNN1R, \n",
    "                                                                                                  modelNames[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Evaluate MTMECNN_1 Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN1S, f0TrajMTMECNN1S = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[1], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=True, isMT=True)\n",
    "f0CentsMTMECNN1S, voicingMTMECNN1S = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN1S)\n",
    "VR_MTMECNN1S, VFA_MTMECNN1S, RPA_MTMECNN1S, RCA_MTMECNN1S, OA_MTMECNN1S = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN1S, f0CentsMTMECNN1S, \n",
    "                                                                                                  modelNames[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Evaluate MTMECNN_2 Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN2R, f0TrajMTMECNN2R = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[2], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=False, isMT=True)\n",
    "f0CentsMTMECNN2R, voicingMTMECNN2R = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN2R)\n",
    "VR_MTMECNN2R, VFA_MTMECNN2R, RPA_MTMECNN2R, RCA_MTMECNN2R, OA_MTMECNN2R = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN2R, f0CentsMTMECNN2R, \n",
    "                                                                                                  modelNames[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Evaluate MTMECNN_2 Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN2S, f0TrajMTMECNN2S = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[2], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=True, isMT=True)    \n",
    "f0CentsMTMECNN2S, voicingMTMECNN2S = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN2S)\n",
    "VR_MTMECNN2S, VFA_MTMECNN2S, RPA_MTMECNN2S, RCA_MTMECNN2S, OA_MTMECNN2S = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN2S, f0CentsMTMECNN2S, \n",
    "                                                                                                  modelNames[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Evaluate MTMECNN_3 Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN3R, f0TrajMTMECNN3R = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[3], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=False, isMT=True)\n",
    "f0CentsMTMECNN3R, voicingMTMECNN3R = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN3R)\n",
    "VR_MTMECNN3R, VFA_MTMECNN3R, RPA_MTMECNN3R, RCA_MTMECNN3R, OA_MTMECNN3R = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN3R, f0CentsMTMECNN3R, \n",
    "                                                                                                  modelNames[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Evaluate MTMECNN_3 Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN3S, f0TrajMTMECNN3S = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[3], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=True, isMT=True)\n",
    "f0CentsMTMECNN3S, voicingMTMECNN3S = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN3S)\n",
    "VR_MTMECNN3S, VFA_MTMECNN3S, RPA_MTMECNN3S, RCA_MTMECNN3S, OA_MTMECNN3S = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN3S, f0CentsMTMECNN3S, \n",
    "                                                                                                  modelNames[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Evaluate MTMECNN_4 Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN4R, f0TrajMTMECNN4R = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[4], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=False, isMT=True)\n",
    "f0CentsMTMECNN4R, voicingMTMECNN4R = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN4R)\n",
    "VR_MTMECNN4R, VFA_MTMECNN4R, RPA_MTMECNN4R, RCA_MTMECNN4R, OA_MTMECNN4R = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN4R, f0CentsMTMECNN4R, \n",
    "                                                                                                  modelNames[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Evaluate MTMECNN_4 Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN4S, f0TrajMTMECNN4S = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[4], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=True, isMT=True)    \n",
    "f0CentsMTMECNN4S, voicingMTMECNN4S = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN4S)\n",
    "VR_MTMECNN4S, VFA_MTMECNN4S, RPA_MTMECNN4S, RCA_MTMECNN4S, OA_MTMECNN4S = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN4S, f0CentsMTMECNN4S, \n",
    "                                                                                                  modelNames[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16: Evaluate MTMECNN_5 Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN5R, f0TrajMTMECNN5R = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[5], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=False, isMT=True)\n",
    "f0CentsMTMECNN5R, voicingMTMECNN5R = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN5R)\n",
    "VR_MTMECNN5R, VFA_MTMECNN5R, RPA_MTMECNN5R, RCA_MTMECNN5R, OA_MTMECNN5R = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN5R, f0CentsMTMECNN5R, \n",
    "                                                                                                  modelNames[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17: Evaluate MTMECNN_5 Smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesMTMECNN5S, f0TrajMTMECNN5S = evaluation.getVMECNNf0Traj(XTestPoly, \n",
    "                                                             modelsEval[5], path_MTME, labelFile, path_data, \n",
    "                                                             smooth=True, isMT=True)\n",
    "f0CentsMTMECNN5S, voicingMTMECNN5S = evaluation.getf0CentsVoicingArrays(f0TrajMTMECNN5S)\n",
    "VR_MTMECNN5S, VFA_MTMECNN5S, RPA_MTMECNN5S, RCA_MTMECNN5S, OA_MTMECNN5S = evaluation.getMEmetrics(voicingGT, f0CentsGT, \n",
    "                                                                                                  voicingMTMECNN5S, f0CentsMTMECNN5S, \n",
    "                                                                                                  modelNames[13])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
